{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agwL8iwQuC9g",
        "outputId": "21c49095-14e8-4808-a712-b6283ed1656c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting scikit-learn==1.5.2\n",
            "  Downloading scikit_learn-1.5.2-cp313-cp313-win_amd64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\eduar\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn==1.5.2) (2.2.2)\n",
            "Collecting scipy>=1.6.0 (from scikit-learn==1.5.2)\n",
            "  Downloading scipy-1.15.1-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
            "Collecting joblib>=1.2.0 (from scikit-learn==1.5.2)\n",
            "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting threadpoolctl>=3.1.0 (from scikit-learn==1.5.2)\n",
            "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
            "Downloading scikit_learn-1.5.2-cp313-cp313-win_amd64.whl (11.0 MB)\n",
            "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
            "   --------------- ------------------------ 4.2/11.0 MB 25.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 11.0/11.0 MB 28.6 MB/s eta 0:00:00\n",
            "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
            "Downloading scipy-1.15.1-cp313-cp313-win_amd64.whl (43.6 MB)\n",
            "   ---------------------------------------- 0.0/43.6 MB ? eta -:--:--\n",
            "   ------ --------------------------------- 7.3/43.6 MB 36.6 MB/s eta 0:00:01\n",
            "   ------------- -------------------------- 14.9/43.6 MB 36.7 MB/s eta 0:00:01\n",
            "   -------------------- ------------------- 22.0/43.6 MB 35.6 MB/s eta 0:00:01\n",
            "   -------------------------- ------------- 29.1/43.6 MB 35.0 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 36.7/43.6 MB 35.2 MB/s eta 0:00:01\n",
            "   ---------------------------------------  43.5/43.6 MB 34.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 43.6/43.6 MB 32.3 MB/s eta 0:00:00\n",
            "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
            "Successfully installed joblib-1.4.2 scikit-learn-1.5.2 scipy-1.15.1 threadpoolctl-3.5.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
            "[notice] To update, run: C:\\Python313\\python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "#!pip install scikit-learn==1.5.2\n",
        "# run this line without the '!' in your terminal to have it installed locally\n",
        "# then you can skip running this\n",
        "\n",
        "\n",
        "\n",
        "# create days_since_april_1 column\n",
        "# convert dateTime to days out of 365\n",
        "# for each value, add 365, subtract april 1st as a number of days\n",
        "# for each value, mod by 365"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mA0HPVmIBT4C"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Load dataset\n",
        "#housing = pd.read_csv('https://raw.githubusercontent.com/byui-cse/cse450-course/master/data/housing.csv', dtype={'id': str})\n",
        "# Load the holdout dataset\n",
        "#holdout_data = pd.read_csv('https://raw.githubusercontent.com/byui-cse/cse450-course/master/data/housing_holdout_test_mini.csv', dtype={'id': str})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "StiU5QcPPxqQ"
      },
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "housing = pd.read_csv('https://raw.githubusercontent.com/byui-cse/cse450-course/master/data/housing.csv', dtype={'id': str})\n",
        "\n",
        "# seperating id column to match major and minor.\n",
        "housing['Major'] = housing['id'].str[:-4]\n",
        "housing['Minor'] = housing['id'].str[-4:].astype(int).astype(str)\n",
        "# now combining again, this is to get rid of trailing and leading zeros to elimate more duplicates\n",
        "housing['more'] = housing['Major'].astype(str) + 'm' + housing['Minor'].astype(str)\n",
        "\n",
        "# now inner joing county data set with training or prediction data set\n",
        "df2 = pd.read_csv(\"C://git//ml//housing_project//testcode//merged_data_5.csv\", dtype={'more': str})\n",
        "\n",
        "housing['more'] = housing['more'].astype(str)\n",
        "df2['more'] = df2['more'].astype(str)\n",
        "\n",
        "housing = housing.merge(df2, on='more', how='inner')\n",
        "\n",
        "\n",
        "\n",
        "y = np.log1p(housing[\"price\"])  # Log transform target\n",
        "\n",
        "X = housing.drop([\"price\", \"id\", \"date\", \"Major_x\", \"Minor_x\", \"more\", \"AcctNbr\", \"Major_y\", \"Minor_y\", \"ZipCode\", \"SqFtLot\"], axis=1)\n",
        "X = pd.get_dummies(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 19957 entries, 0 to 19956\n",
            "Data columns (total 34 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   bedrooms              19957 non-null  int64  \n",
            " 1   bathrooms             19957 non-null  float64\n",
            " 2   sqft_living           19957 non-null  int64  \n",
            " 3   sqft_lot              19957 non-null  int64  \n",
            " 4   floors                19957 non-null  float64\n",
            " 5   waterfront            19957 non-null  int64  \n",
            " 6   view                  19957 non-null  int64  \n",
            " 7   condition             19957 non-null  int64  \n",
            " 8   grade                 19957 non-null  int64  \n",
            " 9   sqft_above            19957 non-null  int64  \n",
            " 10  sqft_basement         19957 non-null  int64  \n",
            " 11  yr_built              19957 non-null  int64  \n",
            " 12  yr_renovated          19957 non-null  int64  \n",
            " 13  zipcode               19957 non-null  int64  \n",
            " 14  lat                   19957 non-null  float64\n",
            " 15  long                  19957 non-null  float64\n",
            " 16  sqft_living15         19957 non-null  int64  \n",
            " 17  sqft_lot15            19957 non-null  int64  \n",
            " 18  ApprLandVal           19957 non-null  int64  \n",
            " 19  ApprImpsVal           19957 non-null  int64  \n",
            " 20  TaxableLandVal        19957 non-null  int64  \n",
            " 21  TaxableImpsVal        19957 non-null  int64  \n",
            " 22  PugetSound            19957 non-null  int64  \n",
            " 23  LakeWashington        19957 non-null  int64  \n",
            " 24  LakeSammamish         19957 non-null  int64  \n",
            " 25  SmallLakeRiverCreek   19957 non-null  int64  \n",
            " 26  OtherView             19957 non-null  int64  \n",
            " 27  WfntLocation          19957 non-null  int64  \n",
            " 28  WfntFootage           19957 non-null  int64  \n",
            " 29  WfntBank              19957 non-null  int64  \n",
            " 30  WfntPoorQuality       19957 non-null  int64  \n",
            " 31  WfntRestrictedAccess  19957 non-null  int64  \n",
            " 32  TrafficNoise          19957 non-null  int64  \n",
            " 33  AirportNoise          19957 non-null  int64  \n",
            "dtypes: float64(4), int64(30)\n",
            "memory usage: 5.2 MB\n"
          ]
        }
      ],
      "source": [
        "X.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "zUr7LKauv1oU"
      },
      "outputs": [],
      "source": [
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create XGBoost regressor\n",
        "model = xgb.XGBRegressor(objective=\"reg:squarederror\", eval_metric=\"rmse\", subsample=0.6,\n",
        "                         n_estimators=1700, max_depth=6, learning_rate=0.01, colsample_bytree=0.7)\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on test set\n",
        "y_pred = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpwL0PycUlt-",
        "outputId": "bde21f2d-7a3e-4084-8246-17c4d133cf21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "R² Score: 0.9223 0.9315\n",
            "RMSE: 92759.5619\n"
          ]
        }
      ],
      "source": [
        "# Evaluate performance\n",
        "y_non_log_test = np.expm1(y_test)\n",
        "y_non_log_pred = np.expm1(y_pred)\n",
        "\n",
        "mse = mean_squared_error(y_non_log_test, y_non_log_pred)\n",
        "rmse = np.sqrt(mse)  # Compute RMSE\n",
        "# return from a log of cost to cost\n",
        "# rmse = np.expm1(rmse)\n",
        "r2 = r2_score(y_test, y_pred)  # Compute R^2\n",
        "r2_2 = r2_score(y_non_log_test, y_non_log_pred)  # Compute R^2\n",
        "\n",
        "print(f\"R² Score: {r2:.4f} {r2_2:.4f}\")\n",
        "print(f\"RMSE: {rmse:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count    19957.000000\n",
              "mean        82.810242\n",
              "std        398.051608\n",
              "min          0.000000\n",
              "25%          0.000000\n",
              "50%          0.000000\n",
              "75%          0.000000\n",
              "max       2015.000000\n",
              "Name: yr_renovated, dtype: float64"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "housing[\"yr_renovated\"].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pSHFJzvIUpTh"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0       93000m305\n",
            "1       954160m15\n",
            "2      733800m150\n",
            "3       611340m46\n",
            "4       29131m170\n",
            "5       728390m36\n",
            "6     982870m1650\n",
            "7      734960m230\n",
            "8      395940m135\n",
            "9      615020m180\n",
            "10    788960m2020\n",
            "11     615290m332\n",
            "12      387620m70\n",
            "13     177110m130\n",
            "14    143270m1230\n",
            "15    262006m9077\n",
            "16      205000m20\n",
            "17    262611m9028\n",
            "18      886200m75\n",
            "19      25960m790\n",
            "Name: more, dtype: object\n",
            "0     983930m1340\n",
            "1     983930m1340\n",
            "2     983930m1330\n",
            "3     983930m1325\n",
            "4     983930m1320\n",
            "5     983930m1315\n",
            "6     983930m1310\n",
            "7     983930m1305\n",
            "8     983930m1300\n",
            "9     983930m1295\n",
            "10    983930m1290\n",
            "11    983930m1285\n",
            "12    983930m1280\n",
            "13    983930m1275\n",
            "14    983930m1270\n",
            "15    983930m1265\n",
            "16    983930m1255\n",
            "17    983930m1250\n",
            "18    983930m1245\n",
            "19    983930m1240\n",
            "Name: more, dtype: object\n"
          ]
        }
      ],
      "source": [
        "# Load the holdout dataset\n",
        "holdout_data = pd.read_csv('https://raw.githubusercontent.com/byui-cse/cse450-course/master/data/housing_holdout_test_mini.csv', dtype={'id': str})\n",
        "\n",
        "\n",
        "# seperating id column to match major and minor.\n",
        "holdout_data['Major'] = holdout_data['id'].str[:-4]\n",
        "holdout_data['Minor'] = holdout_data['id'].str[-4:].astype(int).astype(str)\n",
        "# now combining again, this is to get rid of trailing and leading zeros to elimate more duplicates\n",
        "holdout_data['more'] = holdout_data['Major'].astype(str) + 'm' + holdout_data['Minor'].astype(str)\n",
        "\n",
        "# now inner joing county data set with training or prediction data set\n",
        "df2 = pd.read_csv(\"C://git//ml//housing_project//testcode//merged_data_5.csv\", dtype={'more': str})\n",
        "\n",
        "holdout_data['more'] = holdout_data['more'].astype(str)\n",
        "df2['more'] = df2['more'].astype(str)\n",
        "\n",
        "holdout_data = holdout_data.merge(df2, on='more', how='inner')\n",
        "\n",
        "#print(holdout_data['more'].head(20))\n",
        "#print(df2['more'].head(20))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Drop unnecessary columns\n",
        "X_holdout = holdout_data.drop([\"id\", \"date\", \"Major_x\", \"Minor_x\", \"more\", \"AcctNbr\", \"Major_y\", \"Minor_y\", \"ZipCode\", \"SqFtLot\"], axis=1)\n",
        "\n",
        "# Predict using the trained model\n",
        "y_holdout_pred = model.predict(X_holdout)\n",
        "\n",
        "# Convert predictions back to original scale\n",
        "y_holdout_pred_original = np.expm1(y_holdout_pred)\n",
        "\n",
        "# Create DataFrame with correct format\n",
        "predictions_df = pd.DataFrame({\"price\": y_holdout_pred_original})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N72SaSyjzE3D",
        "outputId": "ded9a94f-28fb-4162-cd40-1dd981c24f43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predictions saved as team8-module3-predictions.csv\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Save in the required format\n",
        "team_name = \"team8\"  # Replace with your actual team name\n",
        "filename = f\"{team_name}-module3-predictions.csv\"\n",
        "predictions_df.to_csv(filename, index=False)\n",
        "\n",
        "print(f\"Predictions saved as {filename}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "84162.24391723484"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.metrics import root_mean_squared_error, r2_score\n",
        "actual_df = pd.read_csv(\"https://raw.githubusercontent.com/byui-cse/cse450-course/refs/heads/master/data/housing_holdout_test_mini_answers.csv\")\n",
        "rmse = root_mean_squared_error(actual_df, predictions_df)\n",
        "rmse"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
