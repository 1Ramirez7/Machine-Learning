{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "class BoostClass:\n",
    "    r2 =0\n",
    "    rmse = 0\n",
    "    n_estimators = 0\n",
    "    max_depth = 0\n",
    "    model = None\n",
    "\n",
    "    def __init__(self, r2 ,rmse , n_estimators , max_depth,model ):\n",
    "        self.r2 =r2\n",
    "        self.rmse = rmse\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.model = model\n",
    "\n",
    "    def toString(self):\n",
    "        return \"r2: \" , self.r2 , \", rmse:\" , self.rmse , \", n_estimators:\" , self.n_estimators , \", max depth:\" , self.max_depth\n",
    "\n",
    "def fixData(housing):\n",
    "    \"\"\"Take out the column to predict before applying this method\"\"\"\n",
    "    # Convert the date column to datetime format\n",
    "    housing['date'] = pd.to_datetime(housing['date'], format='%Y%m%dT%H%M%S')\n",
    "\n",
    "    housing['day'] = housing['date'].dt.day\n",
    "    # Calculate the number of days in the current year\n",
    "    housing['days_since_april_1st'] = (housing['date'].dt.dayofyear + 365 - 91) % 365\n",
    "\n",
    "    housing = housing.drop([\"price\", \"id\", \"date\", \"day\"], axis=1)\n",
    "\n",
    "    # Add total sqft to housing\n",
    "    housing[\"total_sqft\"] = housing[\"sqft_basement\"] + housing[\"sqft_living\"]\n",
    "    # housing[\"age_since_renovation\"] = 2025 - housing[\"yr_renovated\"] if housing[\"yr_renovated\"] != 0 else 2025 - housing[\"yr_built\"]\n",
    "    # Calculate age since renovation or age since built\n",
    "    housing[\"age_since_renovation\"] = housing.apply(lambda row: 2025 - row[\"yr_renovated\"] if row[\"yr_renovated\"] != 0 else 2025 - row[\"yr_built\"], axis=1)\n",
    "\n",
    "    # turn zip code into category\n",
    "    housing[\"zipcode\"] = housing[\"zipcode\"].astype(\"category\")\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "    for sqft in ['sqft_basement', 'sqft_living', 'sqft_lot', 'sqft_above', 'sqft_living15', 'sqft_lot15', 'total_sqft']:\n",
    "        housing[sqft] = scaler.fit_transform(housing[[sqft]])\n",
    "\n",
    "    return housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn==1.5.2 in c:\\users\\12086\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\12086\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn==1.5.2) (2.1.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\12086\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn==1.5.2) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\12086\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn==1.5.2) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\12086\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn==1.5.2) (3.5.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn==1.5.2\n",
    "# run this line without the '!' in your terminal to have it installed locally\n",
    "# then you can skip running this\n",
    "\n",
    "\n",
    "\n",
    "# create days_since_april_1 column\n",
    "# convert dateTime to days out of 365\n",
    "# for each value, add 365, subtract april 1st as a number of days\n",
    "# for each value, mod by 365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   bedrooms  bathrooms  sqft_living  sqft_lot  floors  waterfront  view  \\\n",
      "0         4       3.25     0.261887  0.003569     2.0           0     0   \n",
      "1         3       1.75     0.088302  0.006253     1.0           0     0   \n",
      "2         4       1.00     0.079245  0.004535     1.5           0     2   \n",
      "3         3       1.75     0.086792  0.006468     1.0           0     0   \n",
      "4         2       1.50     0.112453  0.003633     1.0           0     0   \n",
      "\n",
      "   condition  grade  sqft_above  ...  yr_built  yr_renovated  zipcode  \\\n",
      "0          3      8    0.268640  ...      2007             0    98038   \n",
      "1          2      7    0.082237  ...      1979             0    98023   \n",
      "2          3      7    0.115132  ...      1914             0    98116   \n",
      "3          3      8    0.126096  ...      1985             0    98023   \n",
      "4          4      7    0.086623  ...      1947             0    98117   \n",
      "\n",
      "       lat     long  sqft_living15  sqft_lot15  days_since_april_1st  \\\n",
      "0  47.3862 -122.048       0.495784    0.003885                   217   \n",
      "1  47.3035 -122.382       0.156772    0.008287                   289   \n",
      "2  47.5658 -122.389       0.258303    0.005915                   196   \n",
      "3  47.3187 -122.390       0.239374    0.007854                   251   \n",
      "4  47.6859 -122.395       0.222165    0.006101                   136   \n",
      "\n",
      "   total_sqft  age_since_renovation  \n",
      "0    0.258343                  18.0  \n",
      "1    0.091484                  46.0  \n",
      "2    0.060414                 111.0  \n",
      "3    0.066168                  40.0  \n",
      "4    0.126007                  78.0  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "housing = pd.read_csv('https://raw.githubusercontent.com/byui-cse/cse450-course/master/data/housing.csv')\n",
    "y = np.log1p(housing[\"price\"])  # Log transform target\n",
    "\n",
    "X = fixData(housing)\n",
    "print(X.head())\n",
    "X = pd.get_dummies(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT RUN MORE THAN ONCE, we want to keep these variables\n",
    "boostClassList = []\n",
    "bestClass = None\n",
    "# best RMSE so far is ~127000\n",
    "# 1700 n-estimators, 5 depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000 entries, 0 to 19999\n",
      "Data columns (total 18 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   bedrooms       20000 non-null  int64  \n",
      " 1   bathrooms      20000 non-null  float64\n",
      " 2   sqft_living    20000 non-null  int64  \n",
      " 3   sqft_lot       20000 non-null  int64  \n",
      " 4   floors         20000 non-null  float64\n",
      " 5   waterfront     20000 non-null  int64  \n",
      " 6   view           20000 non-null  int64  \n",
      " 7   condition      20000 non-null  int64  \n",
      " 8   grade          20000 non-null  int64  \n",
      " 9   sqft_above     20000 non-null  int64  \n",
      " 10  sqft_basement  20000 non-null  int64  \n",
      " 11  yr_built       20000 non-null  int64  \n",
      " 12  yr_renovated   20000 non-null  int64  \n",
      " 13  zipcode        20000 non-null  int64  \n",
      " 14  lat            20000 non-null  float64\n",
      " 15  long           20000 non-null  float64\n",
      " 16  sqft_living15  20000 non-null  int64  \n",
      " 17  sqft_lot15     20000 non-null  int64  \n",
      "dtypes: float64(4), int64(14)\n",
      "memory usage: 2.7 MB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² Score: 0.7560 - 0.6177\n",
      "RMSE: 240133.7821\n",
      "estimators:  1720 , depth:  6\n",
      "R² Score: 0.7807 - 0.6455\n",
      "RMSE: 231225.0406\n",
      "estimators:  1720 , depth:  6\n",
      "R² Score: 0.7956 - 0.6623\n",
      "RMSE: 225695.8794\n",
      "estimators:  1720 , depth:  6\n",
      "R² Score: 0.8050 - 0.6721\n",
      "RMSE: 222381.1891\n",
      "estimators:  1720 , depth:  6\n",
      "R² Score: 0.8106 - 0.6788\n",
      "RMSE: 220111.1730\n",
      "estimators:  1720 , depth:  6\n",
      "R² Score: 0.8145 - 0.6830\n",
      "RMSE: 218651.0569\n",
      "estimators:  1720 , depth:  6\n",
      "R² Score: 0.8176 - 0.6858\n",
      "RMSE: 217690.4189\n",
      "estimators:  1720 , depth:  6\n",
      "R² Score: 0.8195 - 0.6877\n",
      "RMSE: 217015.6205\n",
      "estimators:  1720 , depth:  6\n",
      "R² Score: 0.8575 - 0.7991\n",
      "RMSE: 174064.8262\n",
      "estimators:  1720 , depth:  6\n",
      "R² Score: 0.8695 - 0.8150\n",
      "RMSE: 167057.5290\n",
      "estimators:  1720 , depth:  6\n",
      "R² Score: 0.8760 - 0.8243\n",
      "RMSE: 162800.9947\n",
      "estimators:  1720 , depth:  6\n",
      "R² Score: 0.8796 - 0.8306\n",
      "RMSE: 159842.5073\n",
      "estimators:  1720 , depth:  6\n",
      "R² Score: 0.8815 - 0.8339\n",
      "RMSE: 158264.5429\n",
      "estimators:  1720 , depth:  6\n",
      "R² Score: 0.8826 - 0.8362\n",
      "RMSE: 157159.2876\n",
      "estimators:  1720 , depth:  6\n",
      "R² Score: 0.8822 - 0.8359\n",
      "RMSE: 157341.9531\n",
      "estimators:  1720 , depth:  6\n",
      "R² Score: 0.8821 - 0.8355\n",
      "RMSE: 157503.1149\n",
      "estimators:  1720 , depth:  6\n",
      "R² Score: 0.8824 - 0.8477\n",
      "RMSE: 151558.5090\n",
      "estimators:  1720 , depth:  6\n",
      "R² Score: 0.8893 - 0.8565\n",
      "RMSE: 147123.1466\n",
      "estimators:  1720 , depth:  6\n",
      "R² Score: 0.8925 - 0.8607\n",
      "RMSE: 144944.9731\n",
      "estimators:  1720 , depth:  6\n",
      "R² Score: 0.8947 - 0.8646\n",
      "RMSE: 142875.9648\n",
      "estimators:  1720 , depth:  6\n",
      "R² Score: 0.8951 - 0.8661\n",
      "RMSE: 142097.4760\n",
      "estimators:  1720 , depth:  6\n",
      "R² Score: 0.8946 - 0.8673\n",
      "RMSE: 141465.0350\n",
      "estimators:  1720 , depth:  6\n",
      "R² Score: 0.8940 - 0.8667\n",
      "RMSE: 141806.5477\n",
      "estimators:  1720 , depth:  6\n",
      "R² Score: 0.8936 - 0.8649\n",
      "RMSE: 142755.9271\n",
      "estimators:  1720 , depth:  6\n",
      "R² Score: 0.8925 - 0.8654\n",
      "RMSE: 142461.0074\n",
      "estimators:  1720 , depth:  6\n",
      "R² Score: 0.8964 - 0.8692\n",
      "RMSE: 140449.7134\n",
      "estimators:  1720 , depth:  6\n",
      "R² Score: 0.8987 - 0.8733\n",
      "RMSE: 138247.5128\n",
      "estimators:  1720 , depth:  6\n",
      "R² Score: 0.8998 - 0.8768\n",
      "RMSE: 136334.0121\n",
      "estimators:  1720 , depth:  6\n",
      "R² Score: 0.8999 - 0.8774\n",
      "RMSE: 135969.4573\n",
      "estimators:  1720 , depth:  6\n",
      "R² Score: 0.8997 - 0.8774\n",
      "RMSE: 135986.4640\n",
      "estimators:  1720 , depth:  6\n",
      "R² Score: 0.8989 - 0.8763\n",
      "RMSE: 136601.4831\n",
      "estimators:  1720 , depth:  6\n",
      "R² Score: 0.8988 - 0.8767\n",
      "RMSE: 136379.8410\n",
      "estimators:  1720 , depth:  6\n",
      "R² Score: 0.8977 - 0.8724\n",
      "RMSE: 138710.9969\n",
      "estimators:  1720 , depth:  6\n",
      "R² Score: 0.9009 - 0.8775\n",
      "RMSE: 135911.9591\n",
      "estimators:  1720 , depth:  6\n",
      "R² Score: 0.9021 - 0.8795\n",
      "RMSE: 134785.9859\n",
      "estimators:  1720 , depth:  6\n",
      "R² Score: 0.9027 - 0.8826\n",
      "RMSE: 133084.3063\n",
      "estimators:  1720 , depth:  6\n",
      "R² Score: 0.9027 - 0.8830\n",
      "RMSE: 132834.8934\n",
      "estimators:  1720 , depth:  6\n",
      "R² Score: 0.9023 - 0.8834\n",
      "RMSE: 132623.3711\n",
      "estimators:  1720 , depth:  6\n",
      "R² Score: 0.9023 - 0.8843\n",
      "RMSE: 132115.8585\n",
      "estimators:  1720 , depth:  6\n",
      "R² Score: 0.9017 - 0.8829\n",
      "RMSE: 132916.0995\n",
      "estimators:  1720 , depth:  6\n",
      "R² Score: 0.9010 - 0.8783\n",
      "RMSE: 135487.1008\n",
      "estimators:  1720 , depth:  6\n",
      "R² Score: 0.9032 - 0.8820\n",
      "RMSE: 133419.7469\n",
      "estimators:  1720 , depth:  6\n",
      "R² Score: 0.9043 - 0.8829\n",
      "RMSE: 132876.7949\n",
      "estimators:  1720 , depth:  6\n",
      "R² Score: 0.9042 - 0.8842\n",
      "RMSE: 132153.0221\n",
      "estimators:  1720 , depth:  6\n",
      "R² Score: 0.9043 - 0.8858\n",
      "RMSE: 131246.1912\n",
      "estimators:  1720 , depth:  6\n",
      "R² Score: 0.9040 - 0.8853\n",
      "RMSE: 131547.9089\n",
      "estimators:  1720 , depth:  6\n",
      "R² Score: 0.9042 - 0.8873\n",
      "RMSE: 130368.7883\n",
      "estimators:  1720 , depth:  6\n",
      "R² Score: 0.9037 - 0.8865\n",
      "RMSE: 130852.5165\n",
      "estimators:  1720 , depth:  6\n",
      "R² Score: 0.9031 - 0.8821\n",
      "RMSE: 133327.1329\n",
      "estimators:  1720 , depth:  6\n",
      "R² Score: 0.9046 - 0.8831\n",
      "RMSE: 132767.3130\n",
      "estimators:  1720 , depth:  6\n",
      "R² Score: 0.9056 - 0.8853\n",
      "RMSE: 131549.2371\n",
      "estimators:  1720 , depth:  6\n",
      "R² Score: 0.9058 - 0.8872\n",
      "RMSE: 130418.9270\n",
      "estimators:  1720 , depth:  6\n",
      "R² Score: 0.9054 - 0.8883\n",
      "RMSE: 129804.6186\n",
      "estimators:  1720 , depth:  6\n",
      "R² Score: 0.9057 - 0.8883\n",
      "RMSE: 129793.3102\n",
      "estimators:  1720 , depth:  6\n",
      "R² Score: 0.9052 - 0.8884\n",
      "RMSE: 129738.4616\n",
      "estimators:  1720 , depth:  6\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[97], line 21\u001b[0m\n\u001b[0;32m     17\u001b[0m model \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mXGBRegressor(objective\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreg:squarederror\u001b[39m\u001b[38;5;124m\"\u001b[39m, eval_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrmse\u001b[39m\u001b[38;5;124m\"\u001b[39m, subsample\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.6\u001b[39m,\n\u001b[0;32m     18\u001b[0m                     n_estimators\u001b[38;5;241m=\u001b[39mn, max_depth\u001b[38;5;241m=\u001b[39md, learning_rate\u001b[38;5;241m=\u001b[39ml, colsample_bytree\u001b[38;5;241m=\u001b[39mcolsample)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Make predictions on test set\u001b[39;00m\n\u001b[0;32m     24\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32mc:\\Users\\12086\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\12086\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\sklearn.py:1170\u001b[0m, in \u001b[0;36mXGBModel.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[0;32m   1167\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1169\u001b[0m model, metric, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_fit(xgb_model, params)\n\u001b[1;32m-> 1170\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1171\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1172\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1173\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1176\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1178\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1179\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1182\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1184\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_evaluation_result(evals_result)\n\u001b[0;32m   1185\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\12086\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\12086\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:182\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    180\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    181\u001b[0m     bst\u001b[38;5;241m.\u001b[39mupdate(dtrain, iteration\u001b[38;5;241m=\u001b[39mi, fobj\u001b[38;5;241m=\u001b[39mobj)\n\u001b[1;32m--> 182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcb_container\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mafter_iteration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevals\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    183\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    185\u001b[0m bst \u001b[38;5;241m=\u001b[39m cb_container\u001b[38;5;241m.\u001b[39mafter_training(bst)\n",
      "File \u001b[1;32mc:\\Users\\12086\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\callback.py:258\u001b[0m, in \u001b[0;36mCallbackContainer.after_iteration\u001b[1;34m(self, model, epoch, dtrain, evals)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, name \u001b[38;5;129;01min\u001b[39;00m evals:\n\u001b[0;32m    257\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m name\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset name should not contain `-`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 258\u001b[0m score: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_set\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_output_margin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    259\u001b[0m metric_score \u001b[38;5;241m=\u001b[39m _parse_eval_str(score)\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_history(metric_score, epoch)\n",
      "File \u001b[1;32mc:\\Users\\12086\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:2212\u001b[0m, in \u001b[0;36mBooster.eval_set\u001b[1;34m(self, evals, iteration, feval, output_margin)\u001b[0m\n\u001b[0;32m   2209\u001b[0m evnames \u001b[38;5;241m=\u001b[39m c_array(ctypes\u001b[38;5;241m.\u001b[39mc_char_p, [c_str(d[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m evals])\n\u001b[0;32m   2210\u001b[0m msg \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mc_char_p()\n\u001b[0;32m   2211\u001b[0m _check_call(\n\u001b[1;32m-> 2212\u001b[0m     \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterEvalOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2213\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2214\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2215\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdmats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2216\u001b[0m \u001b[43m        \u001b[49m\u001b[43mevnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2217\u001b[0m \u001b[43m        \u001b[49m\u001b[43mc_bst_ulong\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mevals\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2218\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2220\u001b[0m )\n\u001b[0;32m   2221\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m msg\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2222\u001b[0m res \u001b[38;5;241m=\u001b[39m msg\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;241m.\u001b[39mdecode()  \u001b[38;5;66;03m# pylint: disable=no-member\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Create XGBoost regressor\n",
    "#1720, depth 6\n",
    "\n",
    "best_l = None\n",
    "best_cols = None\n",
    "\n",
    "for l in range(1, 11, 1):\n",
    "    l = l/1000.0\n",
    "    for colsample in range(3,11,1):\n",
    "        colsample = colsample/10\n",
    "        n = 1720\n",
    "        d = 6\n",
    "        model = xgb.XGBRegressor(objective=\"reg:squarederror\", eval_metric=\"rmse\", subsample=0.6,\n",
    "                            n_estimators=n, max_depth=d, learning_rate=l, colsample_bytree=colsample)\n",
    "\n",
    "        # Train model\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions on test set\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_non_log_test = np.expm1(y_test)\n",
    "        y_non_log_pred = np.expm1(y_pred)\n",
    "\n",
    "        if (best_l == None):\n",
    "            best_l = l\n",
    "        if (best_cols == None):\n",
    "            best_cols = colsample\n",
    "\n",
    "\n",
    "        rmse = root_mean_squared_error(y_non_log_test, y_non_log_pred)\n",
    "        # return from a log of cost to cost\n",
    "        # rmse = np.expm1(rmse)\n",
    "        r2 = r2_score(y_test, y_pred)  # Compute R^2\n",
    "        r2_non_log = r2_score(y_non_log_test, y_non_log_pred)\n",
    "\n",
    "        print(f\"R² Score: {r2:.4f} - {r2_non_log:.4f}\")\n",
    "        print(f\"RMSE: {rmse:.4f}\")\n",
    "        print(\"estimators: \",n,\", depth: \",d)\n",
    "\n",
    "        boostClass = BoostClass(r2, rmse, n, d, model)\n",
    "        boostClassList.append(boostClass)\n",
    "        if (bestClass != None):\n",
    "            if (boostClass.rmse < bestClass.rmse):\n",
    "                bestClass = boostClass\n",
    "                best_l = l\n",
    "                best_cols = colsample\n",
    "        else:\n",
    "            bestClass = boostClass\n",
    "        #r2 =0,rmse = 0, n_estimators = 0, max_depth = 0,model = None\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('r2: ', 0.9058674026993602, ', rmse:', np.float64(126122.8966237912), ', n_estimators:', 1700, ', max depth:', 5)\n",
      "0.001 0.3\n"
     ]
    }
   ],
   "source": [
    "# Evaluate performance\n",
    "print(bestClass.toString())\n",
    "print(best_l, best_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: 0\n",
      "True Negatives: 4000\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.metrics import confusion_matrix\n",
    "# cm = confusion_matrix(y_test, y_pred)\n",
    "# print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the holdout dataset\n",
    "holdout_data = pd.read_csv('https://raw.githubusercontent.com/byui-cse/cse450-course/master/data/housing_holdout_test_mini.csv')\n",
    "\n",
    "# Drop unnecessary columns\n",
    "X_holdout = holdout_data.drop([\"id\", \"date\"], axis=1)\n",
    "\n",
    "# Predict using the trained model\n",
    "y_holdout_pred = model.predict(X_holdout)\n",
    "\n",
    "# Convert predictions back to original scale\n",
    "y_holdout_pred_original = np.expm1(y_holdout_pred)\n",
    "\n",
    "# Create DataFrame with correct format\n",
    "predictions_df = pd.DataFrame({\"price\": y_holdout_pred_original})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved as team8-module3-predictions.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Save in the required format\n",
    "team_name = \"team8\"  # Replace with your actual team name\n",
    "filename = f\"{team_name}-module3-predictions.csv\"\n",
    "predictions_df.to_csv(filename, index=False)\n",
    "\n",
    "print(f\"Predictions saved as {filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
